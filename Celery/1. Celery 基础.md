#### Celery 基础

##### 介绍 

[Celery](https://www.colabug.com/goto/aHR0cDovL3d3dy5jZWxlcnlwcm9qZWN0Lm9yZy8=) 是一个基于消息传递的分布式任务队列。与单纯的消息队列相比较，队列中传递的消息为任务(Task/Job)信息，而不是数据类信息，[Celery](https://www.colabug.com/tag/celery/)基于这些消息完成了任务信息的管理。实现这种任务管理的相似项目还有 [Gearman](https://www.colabug.com/goto/aHR0cDovL2dlYXJtYW4ub3JnLw==) ，只不过这个项目已经很久未更新了，更推荐使用Celery。

Celery 支持同步和异步执行两种模式。同步模式为任务调用方等待任务执行完成，这种方式等同于RPC(Remote Procedure Call)， 异步方式为任务在后台执行，调用方调用后就去做其他工作，之后再根据需要来查看任务结果。Celery自己没有实现消息队列，而是直接已存在的消息队列作为Broker角色。官方推荐的Broker为 [RabbitMQ](https://www.colabug.com/goto/aHR0cDovL3d3dy5yYWJiaXRtcS5jb20v) ，除此之外，Redis、Beanstalkd、MongoDB等也都支持

##### 安装

```shell
pip install celery
```

##### 首先编写服务

> tasks.py

```python
from celery import Celery


# broker 是消息中间件，可以用 rabbitmq 也可以用 redis
# backend 是结果存储的地方，可以用 rabbitmq 也可以用 redis
app = Celery('tasks', broker='amqp://user:password@localhost:5672//',
             backend="redis://:password@localhost:6379/1")

# app = Celery(__name__, broker='redis://localhost', backend='redis://localhost/1')


# 或者使用配置文件
# app.config_from_object("celeryconfig")

@app.task
def taskA(x,y):
	return x + y

@app.task
def taskB(x,y,z):
	return x + y + z

@app.task
def add(x,y):
	return x + y
```

> 配置文件

```python
vi celeryconfig.py

# 使用RabbitMQ作为消息代理
BROKER_URL='amqp://spider:*****@IP:端口/****' 
# 把任务结果存在了Redis
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0' 
# 任务序列化和反序列化使用JSON方案
CELERY_TASK_SERIALIZER = 'json' 
# 读取任务结果使用JSON
CELERY_RESULT_SERIALIZER = 'json' 
# 任务过期时间，不建议直接写86400，应该让这样的magic数字表述更明显
CELERY_TASK_RESULT_EXPIRES = 60 * 60 * 24 
# 指定接受的内容类型，是个数组，可以写多个
CELERY_ACCEPT_CONTENT = ['json'] 
```

##### 启动服务

```sh
# -A 是指定 tasks.py 文件，app 是里面 Celery 对象的名字 -l 是指定日志等级
# 如果是 Windows10 需要 pip install eventlet 然后使用 -P 参数，否则会报错.

# 执行 celery 命令的时候，最好和 使用它的地方 在同一目录，否则会出错。
celery -A tasks.tasks.app worker -l info -P eventlet
```

##### 在项目中使用 celery

> app.py

```python
# 导入 tasks.py 文件中的 test 函数
from tasks import test

# 使用 delay 进行异步执行
task_id = test.delay(1, 2)

# 利用 task_id.get() 方法可以获取返回值
# 或者利用 task_id 去数据库中查询
res = task_id.get(timeout=1)

```



